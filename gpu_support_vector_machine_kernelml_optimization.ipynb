{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "support-vector-machine-kernelml-optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa88P5JUvv_X"
      },
      "source": [
        "## SVM Optimization on a GPU\n",
        "\n",
        "This [notebook](https://colab.research.google.com/drive/1AptayjRoDITNLmyfCc0T7z_xKFBlg2l-) shows the optimization of a multi-class, linear support vector machine using a simulation based optimizer. Any simulation based optimizer could be used with the cuda kernel in this notebook. I used KernelML, my custom optimizer, in this example. The runtime for this script should be set to use the GPU: Runtime->Change runtime type.\n",
        "\n",
        "The original SVM formulation can be found in this paper: [Vapnik 1992](https://www.svms.org/training/BOGV92.pdf). There have been advances to the robustness of the algorithm since then. Please see [Robust Classifier 2019 section 6.1](https://www.mit.edu/~dbertsim/papers/Machine%20Learning%20under%20a%20Modern%20Optimization%20Lens/Robust_Classification.pdf). The robust impementation looks very tedious to implement. If you are interested in implementing it, please consider emailing me as well as looking at KernelML’s documentation. Email: rohankotwani@gmail.com.\n",
        "\n",
        "SVM are typically optimized using Langrage multiplers and quadratic programming. However, this optimization process might not be fast enough, and we want to utilize GPUs. :) We will optimize the SVM primal form with brute force methods. Actually, using a simulation based approach is not such a bad idea because the computational complexity of training an SVM is O(N³), where N is the number of data points.\n",
        "\n",
        "![SVM Primal Form](https://user-images.githubusercontent.com/21232362/70610188-24ef5180-1bd1-11ea-8cad-853b13b26ed8.png)\n",
        "\n",
        "\n",
        "The Iris dataset was used to test the feasibility of using a GPU for simulated based optimization. The dataset has 150 rows and 4 columns. It is a small dataset, but the optimization procedure seems to work. The optimizer's documentation can be found [here](https://github.com/freedomtowin/kernelml/blob/master/README.md) and the cpu parallel implementation of this algorithm can be found [here](https://github.com/freedomtowin/kernelml/blob/master/kernelml-support-vector-machine.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIaTMsoT-dmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b54c613-6101-4c8b-d4f6-4486aaf98925"
      },
      "source": [
        "!apt-get install nvidia-cuda-toolkit\n",
        "!pip3 install numba\n",
        "\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\"\n",
        "\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "import time\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "nvidia-cuda-toolkit is already the newest version (9.1.85-3ubuntu1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " nvidia-cuda-toolkit : Depends: nvidia-cuda-dev (= 9.1.85-3ubuntu1) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.0.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbt0EuPI9lps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c79e18-4813-45ca-a735-60e240ab4814"
      },
      "source": [
        "!cd .. ; find . -name libdevice"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\n",
            "./usr/local/cuda-10.1/nvvm/libdevice\n",
            "./usr/local/cuda-11.0/nvvm/libdevice\n",
            "./usr/local/cuda-10.0/nvvm/libdevice\n",
            "./usr/lib/nvidia-cuda-toolkit/libdevice\n",
            "./usr/lib/cuda/nvvm/libdevice\n",
            "find: ‘./proc/576/task/576/net’: Invalid argument\n",
            "find: ‘./proc/576/net’: Invalid argument\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDce79WK9nJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2d6a9d-6696-4287-93a0-74ee402eb79d"
      },
      "source": [
        "!cd .. ; find . -name libnvvm.so"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
            "./usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\n",
            "./usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
            "find: ‘./proc/576/task/576/net’: Invalid argument\n",
            "find: ‘./proc/576/net’: Invalid argument\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8NOxgzjAmql"
      },
      "source": [
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\"\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE0hKg7u_PxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016c3fc0-13d9-498c-8d3e-3a90b9ba9f79"
      },
      "source": [
        "#test\n",
        "from numba import cuda\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "@cuda.jit\n",
        "def hello(data):\n",
        "    data[cuda.blockIdx.x, cuda.threadIdx.x] = cuda.blockIdx.x\n",
        "\n",
        "numBlocks = 5\n",
        "threadsPerBlock = 10\n",
        "\n",
        "data = np.ones((numBlocks, threadsPerBlock), dtype=np.uint8)\n",
        "\n",
        "hello[numBlocks, threadsPerBlock](data)\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 1 1 1 1]\n",
            " [2 2 2 2 2 2 2 2 2 2]\n",
            " [3 3 3 3 3 3 3 3 3 3]\n",
            " [4 4 4 4 4 4 4 4 4 4]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
            "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so.\n",
            "\n",
            "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
            "  warnings.warn(errors.NumbaWarning(msg))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
            "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/lib/nvidia-cuda-toolkit/libdevice.\n",
            "\n",
            "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
            "  warnings.warn(errors.NumbaWarning(msg))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guF5aryAEWT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462a51b5-6f05-4762-f77e-98c2c73a830d"
      },
      "source": [
        "#install optimizer\n",
        "!pip install kernelml --upgrade"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: kernelml in /usr/local/lib/python3.7/dist-packages (3.41)\n",
            "Requirement already satisfied, skipping upgrade: numba in /usr/local/lib/python3.7/dist-packages (from kernelml) (0.51.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from kernelml) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.7/dist-packages (from kernelml) (0.29.23)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->kernelml) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->kernelml) (0.34.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfA07t-1AyIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acbc6a6-bf8d-42bb-c304-10a0232c1d64"
      },
      "source": [
        "from sklearn import datasets, preprocessing\n",
        "import kernelml\n",
        "from numba import cuda\n",
        "import numba\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy\n",
        "\n",
        "data = datasets.load_iris()\n",
        "y = data.target\n",
        "X = data.data\n",
        "features = data.feature_names\n",
        "\n",
        "print('dataset shape: ',X.shape)\n",
        "print()\n",
        "\n",
        "\n",
        "#the first column is the intercept\n",
        "X = np.column_stack((np.ones(X.shape[0]),X))\n",
        "\n",
        "ohe = preprocessing.OneHotEncoder()\n",
        "\n",
        "y = ohe.fit_transform(y.reshape(-1,1)).toarray()\n",
        "\n",
        "#transform the input for the SVM\n",
        "y = 2*(y-0.5)\n",
        "\n",
        "\n",
        "@cuda.jit('void(float64[:,:,:],float64[:,:], float64[:,:], float64[:,:,:])')\n",
        "def svm_output(out,x,y,w):\n",
        "    t,i,j = cuda.grid(3)\n",
        "    if t<w.shape[2] and i<x.shape[0] and j<y.shape[1]:\n",
        "        for k in range(x.shape[1]):\n",
        "          out[i,j,t] = out[i,j,t] + x[i,k]*w[k,j,t]\n",
        "        out[i,j,t] = 1-out[i,j,t]*y[i,j]\n",
        "        if out[i,j,t]<0:\n",
        "          out[i,j,t] = 0\n",
        "\n",
        "@cuda.jit('void(float64[:],float64[:,:], float64[:,:], float64[:,:,:], float64[:,:,:])')\n",
        "def svm_loss(resX,x,y,w,out):\n",
        "    t = cuda.grid(1)    \n",
        "\n",
        "    if t<w.shape[2]:\n",
        "      \n",
        "      #first column is the intercept\n",
        "      #exclude the first row of the weight matrix since it will map to\n",
        "      #the intercept\n",
        "      for i in range(w.shape[0]):\n",
        "        for j in range(w.shape[1]):\n",
        "          if i>0:\n",
        "            resX[t] = resX[t] + w[i,j,t]*w[i,j,t]\n",
        "\n",
        "      for i in range(out.shape[0]):\n",
        "        for j in range(out.shape[1]):\n",
        "          tmp = 1-out[i,j,t]*y[i,j]\n",
        "          resX[t] = resX[t] + out[i,j,t]\n",
        "\n",
        "def map_losses(X,y,w_list,C):\n",
        "  \n",
        "    N = w_list.shape[1]\n",
        "    w_list = np.ascontiguousarray(w_list.reshape((X.shape[1],y.shape[1],N)))\n",
        "\n",
        "    block_size=(8,32,1)\n",
        "\n",
        "    out = np.zeros((X.shape[0],y.shape[1],N))\n",
        "    d_out = cuda.to_device(out)\n",
        "    \n",
        "    grid_size_i = np.int(np.ceil((N+block_size[0] - 1) / block_size[0]))\n",
        "    grid_size_j = np.int(np.ceil((X.shape[0]+block_size[1] - 1) / block_size[1]))\n",
        "    grid_size_k = np.int(np.ceil((y.shape[1]+block_size[2] - 1) / block_size[2]))\n",
        "\n",
        "    svm_output[[grid_size_i,grid_size_j,grid_size_k], block_size](d_out,X,y,w_list)\n",
        "\n",
        "    result = np.ascontiguousarray(np.zeros(N))\n",
        "    d_result = cuda.to_device(result)\n",
        "\n",
        "    numBlocks = 5\n",
        "    threadsPerBlock = 16\n",
        "\n",
        "    threadsPerBlock = np.int(np.ceil((N+numBlocks - 1) / numBlocks))\n",
        "\n",
        "    svm_loss[threadsPerBlock, numBlocks](d_result,X,y,w_list,d_out)\n",
        "    loss = d_result.copy_to_host()\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "runs = 6\n",
        "zscore = 1.\n",
        "simulation_factor = 300\n",
        "volatility = 10\n",
        "cycles = 20\n",
        "volume = 10\n",
        "\n",
        "kml = kernelml.KernelML(\n",
        "         prior_sampler_fcn=None,\n",
        "         posterior_sampler_fcn=None,\n",
        "         intermediate_sampler_fcn=None,\n",
        "         mini_batch_sampler_fcn=None,\n",
        "         parameter_transform_fcn=None,\n",
        "         loss_calculation_fcn=map_losses,\n",
        "         batch_size=None)\n",
        "\n",
        "C = np.float64(1.0)\n",
        "args_list = [C]\n",
        "\n",
        "kml.optimize(X,y,\n",
        "                                args=args_list,\n",
        "                                number_of_parameters=15,\n",
        "                                number_of_realizations=runs,\n",
        "                                number_of_random_simulations = simulation_factor,\n",
        "                                number_of_cycles=cycles,\n",
        "                                update_volatility = volatility,\n",
        "                                update_volume=volume,\n",
        "                                convergence_z_score=zscore,\n",
        "                                prior_uniform_low=-1,\n",
        "                                prior_uniform_high=1,\n",
        "                                print_feedback=True)\n",
        "\n",
        "def svm(x,w,):\n",
        "    out = x.dot(w)\n",
        "    return out\n",
        "\n",
        "ytrue = data.target\n",
        "\n",
        "print('target:',ytrue)\n",
        "\n",
        "w = kml.kmldata.best_weight_vector.reshape(5,3)\n",
        "\n",
        "ypred = np.argmax(X.dot(w),axis=1)\n",
        "\n",
        "print('predicted:',ypred)\n",
        "\n",
        "print('accuracy:',np.sum(ypred==ytrue)/ytrue.shape[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset shape:  (150, 4)\n",
            "\n",
            "realization 0 loss 158.16097349112712 time 2.520176649093628\n",
            "realization 1 loss 133.2024091569742 time 2.4601633548736572\n",
            "realization 2 loss 121.51214856567874 time 1.8104660511016846\n",
            "realization 3 loss 119.420475668468 time 2.6366240978240967\n",
            "realization 4 loss 120.59664300813047 time 1.370295524597168\n",
            "realization 5 loss 116.70607338779753 time 2.687905788421631\n",
            "target: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1\n",
            " 1 1 1 2 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "accuracy: 0.9466666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkUeYAD2Qnam"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}